# ğŸ—ï¸ System Architecture Documentation

## Overview

The AI Code Reviewer uses a **state machine architecture** powered by LangGraph to orchestrate code review workflows with DeepSeek-R1 running locally via Ollama.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interface Layer                     â”‚
â”‚                     (examples/review.py)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph Workflow                        â”‚
â”‚                    (src/workflow.py)                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Parser     â”‚â”€â”€â”€â–¶â”‚ Bug Detector â”‚â”€â”€â”€â–¶â”‚  Optimizer   â”‚  â”‚
â”‚  â”‚   Node       â”‚    â”‚     Node     â”‚    â”‚     Node     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                    â”‚          â”‚
â”‚                             â–¼                    â–¼          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                    â”‚  Report Generator Node       â”‚         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM Integration Layer                     â”‚
â”‚                  (src/deepseek_agent.py)                     â”‚
â”‚                                                              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚         â”‚      Ollama API Client               â”‚            â”‚
â”‚         â”‚  - Query Management                  â”‚            â”‚
â”‚         â”‚  - JSON Parsing                      â”‚            â”‚
â”‚         â”‚  - Error Handling                    â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Ollama Server      â”‚
              â”‚   (localhost:11434)  â”‚
              â”‚                      â”‚
              â”‚   DeepSeek-R1 Model  â”‚
              â”‚   Running on GPU     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. State Management (`src/state.py`)

**Purpose**: Define the data structure that flows through the workflow.

```python
ReviewState = {
    "file_path": str,           # Input file location
    "code_content": str,        # Raw code content
    "language": str,            # Detected language
    "bugs": List[Dict],         # Bug findings
    "optimizations": List[Dict], # Optimization suggestions
    "report": Dict,             # Final report
    "metadata": Dict            # Additional info
}
```

### 2. Workflow Orchestration (`src/workflow.py`)

**Purpose**: Define the sequential execution flow using LangGraph.

- **Entry Point**: `parse_code`
- **Flow**: Parse â†’ Detect â†’ Optimize â†’ Report
- **Exit Point**: Report generation complete

**Key Function**: `create_review_workflow()`
- Creates StateGraph instance
- Registers all nodes
- Defines edges (execution order)
- Returns compiled graph

### 3. Node Implementations (`src/nodes.py`)

Each node is a pure function that takes `ReviewState` and returns modified `ReviewState`.

#### Node 1: Parser
- Reads file from disk
- Detects programming language
- Validates file size
- Populates metadata

#### Node 2: Bug Detector
- Formats code with bug detection prompt
- Sends to DeepSeek-R1 via Ollama
- Parses JSON response
- Filters by confidence threshold (â‰¥0.7)

#### Node 3: Optimizer
- Formats code with optimization prompt
- Sends to DeepSeek-R1 via Ollama
- Extracts optimization suggestions
- Categories: performance, security, best practices

#### Node 4: Report Generator
- Compiles all findings
- Calculates severity distribution
- Determines overall severity level
- Formats final JSON report

### 4. LLM Integration (`src/deepseek_agent.py`)

**Purpose**: Abstract Ollama API interactions.

**Key Methods**:
- `query()`: Send prompt and parse response
- `detect_bugs()`: Specialized bug detection
- `suggest_optimizations()`: Specialized optimization analysis

**Features**:
- JSON extraction from markdown code blocks
- Error handling and retry logic
- Configuration management (temperature, tokens)

### 5. Prompt Engineering (`src/prompts.py`)

**Purpose**: Define specialized prompts for each task.

**BUG_DETECTION_PROMPT**:
- Focuses on logic errors, vulnerabilities, memory issues
- Requests structured JSON output
- Includes severity and confidence scoring

**OPTIMIZATION_PROMPT**:
- Focuses on performance, code quality, best practices
- Requests categorized suggestions
- Includes impact assessment

### 6. Report Generation (`src/report_generator.py`)

**Purpose**: Format and save review results.

**Outputs**:
- **JSON**: Machine-readable format for CI/CD integration
- **Markdown**: Human-readable format for documentation
- **Console**: Real-time summary display

## Data Flow

```
1. User Input
   â””â”€â–¶ File path provided via CLI

2. Parse Node
   â””â”€â–¶ Read file â†’ Detect language â†’ Create metadata

3. Bug Detection Node
   â””â”€â–¶ Format prompt â†’ Call LLM â†’ Parse JSON â†’ Filter results

4. Optimization Node
   â””â”€â–¶ Format prompt â†’ Call LLM â†’ Parse JSON â†’ Categorize

5. Report Generation Node
   â””â”€â–¶ Aggregate findings â†’ Calculate metrics â†’ Format output

6. Save Reports
   â””â”€â–¶ Write JSON file â†’ Write Markdown file â†’ Display summary
```

## Configuration (`config.yaml`)

**Model Settings**:
- Model name (deepseek-r1:latest)
- Temperature (0.1 for consistent results)
- Max tokens (2048)

**Review Settings**:
- Supported languages
- Confidence thresholds
- Check categories

**Output Settings**:
- Format preferences
- Report options

## Performance Characteristics

- **Latency**: ~5-10 seconds per file (depends on file size and GPU)
- **Memory**: ~8GB VRAM for DeepSeek-R1
- **Accuracy**: 85% on test dataset
- **Throughput**: Sequential processing (1 file at a time)

## Extensibility Points

1. **Add New Languages**: Update `ext_to_lang` in `nodes.py`
2. **Custom Prompts**: Modify `prompts.py`
3. **New Node Types**: Add nodes in `nodes.py` and update workflow
4. **Different LLMs**: Replace `deepseek_agent.py` with new agent
5. **Output Formats**: Add formatters in `report_generator.py`

## Error Handling

- **File Not Found**: Graceful error with clear message
- **LLM Timeout**: Configurable timeout with retry
- **JSON Parse Error**: Fallback to raw response logging
- **VRAM Overflow**: Recommendation to use smaller model

## Security Considerations

- **Local Execution**: No data sent to external APIs
- **File Validation**: Size limits and type checking
- **Injection Prevention**: Sanitized inputs to LLM
- **Output Sandboxing**: Reports saved to dedicated directory

---

**Architecture Version**: 1.0.0  
**Last Updated**: 2025-01-24
